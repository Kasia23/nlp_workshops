{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syjamska sieć neuronowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten notebook przedstawia użycie syjamskiej sieci neuronowej na danych tekstowych.\n",
    "Sieć oparta jest na dwóch modelach blstm o takiej samej architekturze i współdzielonych wagach.\n",
    "\n",
    "Wykorzystamy dane z kaggle dotyczące pytań na Quora i podobieństwa między nimi:\n",
    "https://www.kaggle.com/c/quora-question-pairs\n",
    "\n",
    "Kod podzielony jest na notebooka i skrypty pythonowe, z których zaczytujemy potrzebne funkcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "from utils.preprocessing_utils import clear_text, prepare_representation\n",
    "from utils.model_utils import prepare_embedding_matrix, one_or_zero, build_model_blstm, exponent_neg_manhattan_distance, model_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiujemy timestamp, który umożliwi nam wersjonowanie danych, modelu i tokenizera przy zapisywaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "now = time.strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opis danych ze strony:\n",
    "\n",
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question. Quora values canonical questions because they provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "\n",
    "The goal of this competition is to predict which of the provided pairs of questions contain two questions with the same meaning. \n",
    "\n",
    "Data fields:\n",
    "id - the id of a training set question pair\n",
    "qid1, qid2 - unique ids of each question (only available in train.csv)\n",
    "question1, question2 - the full text of each question\n",
    "is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"src/Siamese_workshops_quora.csv\", index_col=\"id\", nrows=10000)\n",
    "data = data[data['question1'].apply(lambda x: isinstance(x,str))]\n",
    "data = data[data['question2'].apply(lambda x: isinstance(x,str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19404</td>\n",
       "      <td>19405</td>\n",
       "      <td>How would you order these four cities (Bangalo...</td>\n",
       "      <td>What is the cost of living in Europe and the U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19406</td>\n",
       "      <td>19407</td>\n",
       "      <td>Stphen william hawking?</td>\n",
       "      <td>What are the differences between SM, YG and JY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19408</td>\n",
       "      <td>19409</td>\n",
       "      <td>Mathematical Puzzles: What is () + () + () = 3...</td>\n",
       "      <td>What are the steps to solve this equation: [ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19410</td>\n",
       "      <td>19411</td>\n",
       "      <td>Is IMS noida good for BCA?</td>\n",
       "      <td>How good is IMS Noida for studying BCA?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19412</td>\n",
       "      <td>19413</td>\n",
       "      <td>What are the most respected and informative te...</td>\n",
       "      <td>What are Caltech's required and recommended te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid1   qid2                                          question1  \\\n",
       "id                                                                      \n",
       "9995  19404  19405  How would you order these four cities (Bangalo...   \n",
       "9996  19406  19407                            Stphen william hawking?   \n",
       "9997  19408  19409  Mathematical Puzzles: What is () + () + () = 3...   \n",
       "9998  19410  19411                         Is IMS noida good for BCA?   \n",
       "9999  19412  19413  What are the most respected and informative te...   \n",
       "\n",
       "                                              question2  is_duplicate  \n",
       "id                                                                     \n",
       "9995  What is the cost of living in Europe and the U...             0  \n",
       "9996  What are the differences between SM, YG and JY...             0  \n",
       "9997  What are the steps to solve this equation: [ma...             0  \n",
       "9998            How good is IMS Noida for studying BCA?             1  \n",
       "9999  What are Caltech's required and recommended te...             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3711, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_duplicate==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6289, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_duplicate==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czyścimy dane z interpunkcji i lemmatyzujemy tekst. Nie usuwamy stopwordsów, ponieważ ich brak mógłby znacząco zmienić sens pytania.\n",
    "Używamy funkcji clear_text, która przyjmuje argumenty: dane, znaki do usunięcia, czy usuwać stopwordsy i czy lematyzować tekst.\n",
    "Następnie wykonuje szereg zadanych operacji i zwraca pytania podzielone na oczyszczone słowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-11 19:17:39.453541 Oczyszczenie danych - SUKCES\n",
      "2019-04-11 19:17:42.633574 Lemmatyzacja - SUKCES\n",
      "2019-04-11 19:17:42.870540 Oczyszczenie danych - SUKCES\n",
      "2019-04-11 19:17:43.525556 Lemmatyzacja - SUKCES\n"
     ]
    }
   ],
   "source": [
    "for question in ['question1', 'question2']:\n",
    "    strip_chars = punctuation + '„”–'\n",
    "    data[question + '_cleared'] = clear_text(data[question], strip_chars, is_remove_stopwords=False, is_lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleared</th>\n",
       "      <th>question2_cleared</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19404</td>\n",
       "      <td>19405</td>\n",
       "      <td>How would you order these four cities (Bangalo...</td>\n",
       "      <td>What is the cost of living in Europe and the U...</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, would, you, order, these, four, city, ba...</td>\n",
       "      <td>[what, is, the, cost, of, living, in, europe, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19406</td>\n",
       "      <td>19407</td>\n",
       "      <td>Stphen william hawking?</td>\n",
       "      <td>What are the differences between SM, YG and JY...</td>\n",
       "      <td>0</td>\n",
       "      <td>[stphen, william, hawking]</td>\n",
       "      <td>[what, are, the, difference, between, sm, yg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19408</td>\n",
       "      <td>19409</td>\n",
       "      <td>Mathematical Puzzles: What is () + () + () = 3...</td>\n",
       "      <td>What are the steps to solve this equation: [ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mathematical, puzzle, what, is, 30, using, 1,...</td>\n",
       "      <td>[what, are, the, step, to, solve, this, equati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19410</td>\n",
       "      <td>19411</td>\n",
       "      <td>Is IMS noida good for BCA?</td>\n",
       "      <td>How good is IMS Noida for studying BCA?</td>\n",
       "      <td>1</td>\n",
       "      <td>[is, ims, noida, good, for, bca]</td>\n",
       "      <td>[how, good, is, ims, noida, for, studying, bca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19412</td>\n",
       "      <td>19413</td>\n",
       "      <td>What are the most respected and informative te...</td>\n",
       "      <td>What are Caltech's required and recommended te...</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, are, the, most, respected, and, informa...</td>\n",
       "      <td>[what, are, caltech's, required, and, recommen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid1   qid2                                          question1  \\\n",
       "id                                                                      \n",
       "9995  19404  19405  How would you order these four cities (Bangalo...   \n",
       "9996  19406  19407                            Stphen william hawking?   \n",
       "9997  19408  19409  Mathematical Puzzles: What is () + () + () = 3...   \n",
       "9998  19410  19411                         Is IMS noida good for BCA?   \n",
       "9999  19412  19413  What are the most respected and informative te...   \n",
       "\n",
       "                                              question2  is_duplicate  \\\n",
       "id                                                                      \n",
       "9995  What is the cost of living in Europe and the U...             0   \n",
       "9996  What are the differences between SM, YG and JY...             0   \n",
       "9997  What are the steps to solve this equation: [ma...             0   \n",
       "9998            How good is IMS Noida for studying BCA?             1   \n",
       "9999  What are Caltech's required and recommended te...             0   \n",
       "\n",
       "                                      question1_cleared  \\\n",
       "id                                                        \n",
       "9995  [how, would, you, order, these, four, city, ba...   \n",
       "9996                         [stphen, william, hawking]   \n",
       "9997  [mathematical, puzzle, what, is, 30, using, 1,...   \n",
       "9998                   [is, ims, noida, good, for, bca]   \n",
       "9999  [what, are, the, most, respected, and, informa...   \n",
       "\n",
       "                                      question2_cleared  \n",
       "id                                                       \n",
       "9995  [what, is, the, cost, of, living, in, europe, ...  \n",
       "9996  [what, are, the, difference, between, sm, yg, ...  \n",
       "9997  [what, are, the, step, to, solve, this, equati...  \n",
       "9998    [how, good, is, ims, noida, for, studying, bca]  \n",
       "9999  [what, are, caltech's, required, and, recommen...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie i zapisywanie tokenizera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy i zapisujemy tokenizer. Przyda nam się on gdy będziemy chcieli ponownie użyć modelu i przygotować do niego dowolny zbiór danych\n",
    "Używamy funkcji prepare_representation, która przyjmuje dane tekstowe z obydwu pytań (korpus danych), tworzy tokenizer i zwraca zarówno tokenizer jak i ztokenizowaną treść pytań. \n",
    "\n",
    "Argument oov_token: opcjonalny argument, który zostanie dodany do indeksu słów i użyty za każdym razem kiedy pojawi się słowo, które nie było uwzględnione w tokenizerze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, stacked_representation = prepare_representation(\n",
    "    pd.concat([data['question1_cleared'], data['question2_cleared']], axis=0), 'unk')\n",
    "data['question1_tokens'], data['question2_tokens'] = np.array_split(stacked_representation, 2)\n",
    "with open(f\"results/{now}_tokenizer_warsztaty.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleared</th>\n",
       "      <th>question2_cleared</th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19404</td>\n",
       "      <td>19405</td>\n",
       "      <td>How would you order these four cities (Bangalo...</td>\n",
       "      <td>What is the cost of living in Europe and the U...</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, would, you, order, these, four, city, ba...</td>\n",
       "      <td>[what, is, the, cost, of, living, in, europe, ...</td>\n",
       "      <td>[7, 46, 16, 515, 352, 1556, 321, 488, 1018, 65...</td>\n",
       "      <td>[3, 4, 2, 277, 11, 426, 9, 1104, 13, 2, 85, 59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19406</td>\n",
       "      <td>19407</td>\n",
       "      <td>Stphen william hawking?</td>\n",
       "      <td>What are the differences between SM, YG and JY...</td>\n",
       "      <td>0</td>\n",
       "      <td>[stphen, william, hawking]</td>\n",
       "      <td>[what, are, the, difference, between, sm, yg, ...</td>\n",
       "      <td>[11146, 11147, 11148]</td>\n",
       "      <td>[3, 12, 2, 66, 50, 2017, 13747, 13, 13748, 611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19408</td>\n",
       "      <td>19409</td>\n",
       "      <td>Mathematical Puzzles: What is () + () + () = 3...</td>\n",
       "      <td>What are the steps to solve this equation: [ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mathematical, puzzle, what, is, 30, using, 1,...</td>\n",
       "      <td>[what, are, the, step, to, solve, this, equati...</td>\n",
       "      <td>[2985, 2738, 3, 4, 753, 177, 109, 144, 188, 31...</td>\n",
       "      <td>[3, 12, 2, 649, 8, 791, 69, 1308, 192, 1153, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19410</td>\n",
       "      <td>19411</td>\n",
       "      <td>Is IMS noida good for BCA?</td>\n",
       "      <td>How good is IMS Noida for studying BCA?</td>\n",
       "      <td>1</td>\n",
       "      <td>[is, ims, noida, good, for, bca]</td>\n",
       "      <td>[how, good, is, ims, noida, for, studying, bca]</td>\n",
       "      <td>[4, 7873, 5462, 40, 15, 7874]</td>\n",
       "      <td>[7, 40, 4, 7873, 5462, 15, 845, 7874]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19412</td>\n",
       "      <td>19413</td>\n",
       "      <td>What are the most respected and informative te...</td>\n",
       "      <td>What are Caltech's required and recommended te...</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, are, the, most, respected, and, informa...</td>\n",
       "      <td>[what, are, caltech's, required, and, recommen...</td>\n",
       "      <td>[3, 12, 2, 56, 3418, 13, 11149, 2184, 15, 845,...</td>\n",
       "      <td>[3, 12, 13751, 579, 13, 1858, 2184, 15, 2158, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid1   qid2                                          question1  \\\n",
       "id                                                                      \n",
       "9995  19404  19405  How would you order these four cities (Bangalo...   \n",
       "9996  19406  19407                            Stphen william hawking?   \n",
       "9997  19408  19409  Mathematical Puzzles: What is () + () + () = 3...   \n",
       "9998  19410  19411                         Is IMS noida good for BCA?   \n",
       "9999  19412  19413  What are the most respected and informative te...   \n",
       "\n",
       "                                              question2  is_duplicate  \\\n",
       "id                                                                      \n",
       "9995  What is the cost of living in Europe and the U...             0   \n",
       "9996  What are the differences between SM, YG and JY...             0   \n",
       "9997  What are the steps to solve this equation: [ma...             0   \n",
       "9998            How good is IMS Noida for studying BCA?             1   \n",
       "9999  What are Caltech's required and recommended te...             0   \n",
       "\n",
       "                                      question1_cleared  \\\n",
       "id                                                        \n",
       "9995  [how, would, you, order, these, four, city, ba...   \n",
       "9996                         [stphen, william, hawking]   \n",
       "9997  [mathematical, puzzle, what, is, 30, using, 1,...   \n",
       "9998                   [is, ims, noida, good, for, bca]   \n",
       "9999  [what, are, the, most, respected, and, informa...   \n",
       "\n",
       "                                      question2_cleared  \\\n",
       "id                                                        \n",
       "9995  [what, is, the, cost, of, living, in, europe, ...   \n",
       "9996  [what, are, the, difference, between, sm, yg, ...   \n",
       "9997  [what, are, the, step, to, solve, this, equati...   \n",
       "9998    [how, good, is, ims, noida, for, studying, bca]   \n",
       "9999  [what, are, caltech's, required, and, recommen...   \n",
       "\n",
       "                                       question1_tokens  \\\n",
       "id                                                        \n",
       "9995  [7, 46, 16, 515, 352, 1556, 321, 488, 1018, 65...   \n",
       "9996                              [11146, 11147, 11148]   \n",
       "9997  [2985, 2738, 3, 4, 753, 177, 109, 144, 188, 31...   \n",
       "9998                      [4, 7873, 5462, 40, 15, 7874]   \n",
       "9999  [3, 12, 2, 56, 3418, 13, 11149, 2184, 15, 845,...   \n",
       "\n",
       "                                       question2_tokens  \n",
       "id                                                       \n",
       "9995  [3, 4, 2, 277, 11, 426, 9, 1104, 13, 2, 85, 59...  \n",
       "9996  [3, 12, 2, 66, 50, 2017, 13747, 13, 13748, 611...  \n",
       "9997  [3, 12, 2, 649, 8, 791, 69, 1308, 192, 1153, 2...  \n",
       "9998              [7, 40, 4, 7873, 5462, 15, 845, 7874]  \n",
       "9999  [3, 12, 13751, 579, 13, 1858, 2184, 15, 2158, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ustalenie parametrów modelu i podzielenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "        'emb_len': 300,\n",
    "        'lstm_units': 10,\n",
    "        'max_seq_len': 150,\n",
    "        'text_rep_dim': 32,\n",
    "        'batch_size': 64,\n",
    "        'maxlen': 40,\n",
    "        'distance': 'manhattan',\n",
    "        'optimizer': 'adam',\n",
    "        'loss': 'bin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(['qid1', 'qid2'])\n",
    "\n",
    "y = data['is_duplicate'].astype(np.int64).apply(one_or_zero, args=(1,))\n",
    "\n",
    "\n",
    "Y_train, Y_validation, X_train, X_validation = train_test_split(y, data.drop([\"is_duplicate\"], axis=1), test_size=0.2)\n",
    "\n",
    "X_train = X_train.drop([\"question1\",\"question2\", \"question1_cleared\", \"question2_cleared\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <th>2811</th>\n",
       "      <td>[77, 285, 96, 198, 82, 8605, 971, 1611, 13, 82...</td>\n",
       "      <td>[7, 12, 3913, 971, 152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <th>2241</th>\n",
       "      <td>[7, 10, 16, 28, 33, 371, 2268, 21, 4634]</td>\n",
       "      <td>[7, 14, 16, 76, 4634, 8, 5378, 2, 371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18861</th>\n",
       "      <th>18862</th>\n",
       "      <td>[10, 584, 5205, 39, 150, 846, 664, 476, 1336, ...</td>\n",
       "      <td>[4, 5812, 13679, 5, 3748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10842</th>\n",
       "      <th>10843</th>\n",
       "      <td>[9, 2506, 8, 618, 1706, 590, 43, 12, 9851, 39,...</td>\n",
       "      <td>[3, 655, 1103, 31, 6, 618, 29, 5, 8054, 1706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8643</th>\n",
       "      <th>8644</th>\n",
       "      <td>[3, 12, 32, 11, 2, 6629, 2708, 26, 442, 3485, ...</td>\n",
       "      <td>[7, 1179, 4, 6629, 2708, 346]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1_tokens  \\\n",
       "qid1  qid2                                                       \n",
       "2810  2811   [77, 285, 96, 198, 82, 8605, 971, 1611, 13, 82...   \n",
       "2240  2241            [7, 10, 16, 28, 33, 371, 2268, 21, 4634]   \n",
       "18861 18862  [10, 584, 5205, 39, 150, 846, 664, 476, 1336, ...   \n",
       "10842 10843  [9, 2506, 8, 618, 1706, 590, 43, 12, 9851, 39,...   \n",
       "8643  8644   [3, 12, 32, 11, 2, 6629, 2708, 26, 442, 3485, ...   \n",
       "\n",
       "                                          question2_tokens  \n",
       "qid1  qid2                                                  \n",
       "2810  2811                         [7, 12, 3913, 971, 152]  \n",
       "2240  2241          [7, 14, 16, 76, 4634, 8, 5378, 2, 371]  \n",
       "18861 18862                      [4, 5812, 13679, 5, 3748]  \n",
       "10842 10843  [3, 655, 1103, 31, 6, 618, 29, 5, 8054, 1706]  \n",
       "8643  8644                   [7, 1179, 4, 6629, 2708, 346]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = [pad_sequences(X_train['question1_tokens'], maxlen=model_parameters['maxlen']),\n",
    "                   pad_sequences(X_train['question2_tokens'], maxlen=model_parameters['maxlen'])]\n",
    "X_val_dataset = [pad_sequences(X_validation['question1_tokens'], maxlen=model_parameters['maxlen']),\n",
    "                 pad_sequences(X_validation['question2_tokens'], maxlen=model_parameters['maxlen'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[   0,    0,    0, ...,   82, 1964, 3913],\n",
       "        [   0,    0,    0, ..., 2268,   21, 4634],\n",
       "        [   0,    0,    0, ...,  104,  785, 3275],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,   58,  294,  166],\n",
       "        [   0,    0,    0, ...,   40,   13,  223],\n",
       "        [   0,    0,    0, ..., 2680,  144, 9298]]),\n",
       " array([[    0,     0,     0, ...,  3913,   971,   152],\n",
       "        [    0,     0,     0, ...,  5378,     2,   371],\n",
       "        [    0,     0,     0, ..., 13679,     5,  3748],\n",
       "        ...,\n",
       "        [    0,     0,     0, ...,   991, 11693,   819],\n",
       "        [    0,     0,     0, ...,   223,    13,    40],\n",
       "        [    0,     0,     0, ...,   132,     9,  2680]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja prepare_embedding_matrix umożliwia wczytanie przetrenowych embeddingów w2v lub ustawienie parametrów umożliwiające wytrenowanie własnych embeddingów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1001 word vectors\n",
      "number of null word embeddings: 12888\n"
     ]
    }
   ],
   "source": [
    "model_parameters.update({'nb_tokens': len(tokenizer.index_word) + 1})\n",
    "\n",
    "embedding_matrix, embeddings_index, is_trainable = prepare_embedding_matrix(model_parameters, tokenizer.word_index,\n",
    "                                                                            'src/wiki.en.vec.csv', 'fb_emb', nrows=1000)\n",
    "model_parameters.update({'is_trainable': is_trainable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 300)      4125600     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 40, 20)       24880       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 20)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 40, 20)       0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 40, 32)       672         dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1280)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1280)         0           dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,151,152\n",
      "Trainable params: 25,552\n",
      "Non-trainable params: 4,125,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model_blstm(model_parameters, embedding_matrix)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_share = Y_train.sum() / Y_train.shape[0]\n",
    "\n",
    "ones_weight = (1 - ones_share) / ones_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "7200/7200 [==============================] - 25s 3ms/step - loss: 1.1637 - acc: 0.6272 - mean_absolute_error: 0.4174 - cosine_proximity: -0.3715 - val_loss: 1.2868 - val_acc: 0.5350 - val_mean_absolute_error: 0.4823 - val_cosine_proximity: -0.3612\n",
      "Epoch 2/2\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.8093 - acc: 0.6340 - mean_absolute_error: 0.4446 - cosine_proximity: -0.3717 - val_loss: 1.2712 - val_acc: 0.5450 - val_mean_absolute_error: 0.4833 - val_cosine_proximity: -0.3612\n"
     ]
    }
   ],
   "source": [
    "model_trained = model.fit(X_train_dataset, Y_train.values,\n",
    "                          validation_split=0.1, batch_size=model_parameters['batch_size'], epochs=2,\n",
    "                          class_weight={1: ones_weight, 0: 1})\n",
    "\n",
    "model.save(\"results/\" + now + \"_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie wcześniej wytrenowego modelu i tokenizera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "#read tokenizer\n",
    "model = load_model('results/20190411-164644_model.h5', custom_objects={'exponent_neg_manhattan_distance': exponent_neg_manhattan_distance})\n",
    "with open('results/20190411-164644_tokenizer_warsztaty.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "X_validation = X_validation.drop([\"question1_tokens\",\"question2_tokens\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1: Należy ztokenizować dane testowe używając zaczytanego tokenizera i przygotować je w taki sposób aby dało się wykonać na nich model.predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_dataset = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/step\n",
      "[0.35394559454917907, 0.852, 0.2266942652463913, -0.37299996888637543]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_val_dataset, Y_validation.values))\n",
    "preds = model.predict(X_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2: Napisz funkcję calculate_preds_binary(preds), która zwróci binarny wynik z modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-364f40f917ca>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-364f40f917ca>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    #\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def calculate_preds_binary(preds):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba poprawnie przewidzianych ogłoszeń:  1704\n",
      "Liczba wszystkich ogłoszeń w zbiorze testowym:  2000\n",
      "Confusion matrix: \n",
      "Predicted  False  True\n",
      "Actual                \n",
      "False       1039   215\n",
      "True          81   665\n",
      "Metryki: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88      1254\n",
      "           1       0.76      0.89      0.82       746\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2000\n",
      "   macro avg       0.84      0.86      0.85      2000\n",
      "weighted avg       0.86      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_binary = calculate_preds_binary(preds)\n",
    "cm, metrics = model_statistics(preds_binary, Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3: Analiza błędu - Wyświetl pierwsze 5 poprawnie zaklasyfikowanych par i pierwsze 5 niepoprawnie zakwalifikowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
