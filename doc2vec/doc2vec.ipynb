{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from string import punctuation\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "if os.getcwd().endswith(\"doc2vec\"):\n",
    "    # goes one folder \"up\". Can't be run multiple times or your work directory will get rekt\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from doc2vec.constants import GENSIM_MODEL_PATH, TRAIN_PATH, TEST_PATH, PUNC_CHARS, STOPWORDS_SET, SGJP_PATH, \\\n",
    "    TOKENIZER_PATH\n",
    "from doc2vec.preprocess_utils import prepare_sgjp_dict, clear_offers, tokenize_texts, tokenize, \\\n",
    "    prepare_gensim_word_index_dict\n",
    "from doc2vec.model_utils import model_cnn, model_doc2vec, gensim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_data(pickle_path, stopwords_set=None, lemmatize_dict=None, remove_punct=None):\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    data['text'] = data['job_name'].str.cat(data['job_content'], sep=' ')\n",
    "    data.dropna(inplace=True, subset=['text'])  # drop data where we don't have text\n",
    "    return data['label'], clear_offers(data=data, text_col='text', stopwords_list=stopwords_set,\n",
    "                                       lemmatize_dict=lemmatize_dict, remove_punct=remove_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-12 01:30:13.727831  Clearing data - DONE\n",
      "2019-04-12 01:30:14.025829  Removing stopwords - DONE\n",
      "2019-04-12 01:30:15.022792  Lemmatizing - DONE\n",
      "2019-04-12 01:30:15.325831  Clearing data - DONE\n",
      "2019-04-12 01:30:15.353831  Removing stopwords - DONE\n",
      "2019-04-12 01:30:15.451830  Lemmatizing - DONE\n"
     ]
    }
   ],
   "source": [
    "lemmatize_dict = prepare_sgjp_dict(SGJP_PATH)\n",
    "\n",
    "train_labels, train_data_prep = load_preprocess_data(TRAIN_PATH, stopwords_set=STOPWORDS_SET,\n",
    "                                                     lemmatize_dict=lemmatize_dict,\n",
    "                                                     remove_punct=PUNC_CHARS + punctuation\n",
    "                                                     )\n",
    "\n",
    "test_labels, test_data_prep = load_preprocess_data(TEST_PATH, stopwords_set=STOPWORDS_SET,\n",
    "                                                   lemmatize_dict=lemmatize_dict,\n",
    "                                                   remove_punct=PUNC_CHARS + punctuation\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sprzedaż                                    3120\n",
      "Finanse / Ekonomia                          1405\n",
      "Inżynieria                                  1344\n",
      "IT - Rozwój oprogramowania                  1197\n",
      "Administracja biurowa                       1005\n",
      "Produkcja                                    950\n",
      "Human Resources / Zasoby ludzkie             705\n",
      "Praca fizyczna                               696\n",
      "IT - Administracja                           664\n",
      "Obsługa klienta                              416\n",
      "Marketing                                    406\n",
      "Łańcuch dostaw                               375\n",
      "Budownictwo                                  302\n",
      "Hotelarstwo / Gastronomia / Turystyka        247\n",
      "Zakupy                                       198\n",
      "Prawo                                        188\n",
      "Reklama / Grafika / Kreacja / Fotografia     182\n",
      "Transport / Spedycja / Logistyka             179\n",
      "Kontrola jakości                             176\n",
      "Internet / e-Commerce / Nowe media           161\n",
      "Nieruchomości                                146\n",
      "Zdrowie / Uroda / Rekreacja                  137\n",
      "Call Center                                  131\n",
      "Bankowość                                     94\n",
      "Badania i rozwój                              91\n",
      "BHP / Ochrona środowiska                      89\n",
      "Doradztwo / Konsulting                        77\n",
      "Media / Sztuka / Rozrywka                     56\n",
      "Ubezpieczenia                                 56\n",
      "Edukacja / Szkolenia                          56\n",
      "Sektor publiczny                              43\n",
      "Public Relations                              32\n",
      "Energetyka                                    22\n",
      "Inne                                          13\n",
      "Franczyza / Własny biznes                      6\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's see what our labels are\n",
    "print(train_labels.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode our labels\n",
    "all_labels = np.array(train_labels.append(test_labels))\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(all_labels.reshape(-1, 1))\n",
    "\n",
    "train_labels_bin = ohe.transform(train_labels.values.reshape(-1, 1))\n",
    "test_labels_bin = ohe.transform(test_labels.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts for neural network\n",
    "tokenizer, train_tokens = tokenize_texts(train_data_prep, TOKENIZER_PATH, oov_token='unk')\n",
    "test_tokens = tokenizer.texts_to_sequences(test_data_prep.str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    'input_len': 300,\n",
    "    'word_emb_size': 100,\n",
    "    'doc_emb_size': 100,\n",
    "    'filter_sizes': [5, 1],\n",
    "    'num_filters': 300,\n",
    "    'batch_size': 256,\n",
    "    'n_epochs': 10,\n",
    "    'nb_tokens': len(tokenizer.word_index) + 1,\n",
    "    'output_len': len(ohe.categories_[0])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_data_prep)]\n",
    "model = Doc2Vec(documents, vector_size=MODEL_PARAMS['doc_emb_size'], window=2, min_count=1, workers=4)\n",
    "model.save(GENSIM_MODEL_PATH)\n",
    "# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer Doc2Vec representations for docs:\n",
    "train_doc2vec = np.matrix(train_data_prep.apply(model.infer_vector).to_list())\n",
    "test_doc2vec = np.matrix(test_data_prep.apply(model.infer_vector).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad offers\n",
    "train_pad_tokens = pad_sequences(train_tokens, maxlen=MODEL_PARAMS['input_len'])\n",
    "test_pad_tokens = pad_sequences(test_tokens, maxlen=MODEL_PARAMS['input_len'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 300, 100)     3063700     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 300, 300)     150300      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 300, 300)     30300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 3, 300)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 3, 300)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 300)       0           max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1800)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1800)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 70)           126070      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 70)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 35)           2485        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,372,855\n",
      "Trainable params: 3,372,855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 13468 samples, validate on 1497 samples\n",
      "Epoch 1/10\n",
      "13468/13468 [==============================] - 108s 8ms/step - loss: 3.0005 - acc: 0.2033 - val_loss: 2.7319 - val_acc: 0.2158\n",
      "Epoch 2/10\n",
      "13468/13468 [==============================] - 110s 8ms/step - loss: 2.2164 - acc: 0.2089 - val_loss: 1.6006 - val_acc: 0.2271\n",
      "Epoch 3/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 1.2698 - acc: 0.5452 - val_loss: 0.8532 - val_acc: 0.7629\n",
      "Epoch 4/10\n",
      "13468/13468 [==============================] - 53s 4ms/step - loss: 0.7442 - acc: 0.7932 - val_loss: 0.6968 - val_acc: 0.8029\n",
      "Epoch 5/10\n",
      "13468/13468 [==============================] - 53s 4ms/step - loss: 0.5385 - acc: 0.8465 - val_loss: 0.6337 - val_acc: 0.8170\n",
      "Epoch 6/10\n",
      "13468/13468 [==============================] - 53s 4ms/step - loss: 0.3908 - acc: 0.8855 - val_loss: 0.5956 - val_acc: 0.8263\n",
      "Epoch 7/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.2858 - acc: 0.9182 - val_loss: 0.6019 - val_acc: 0.8317\n",
      "Epoch 8/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.2098 - acc: 0.9391 - val_loss: 0.6047 - val_acc: 0.8277\n",
      "Epoch 9/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.1454 - acc: 0.9581 - val_loss: 0.6340 - val_acc: 0.8310\n",
      "Epoch 10/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.1120 - acc: 0.9673 - val_loss: 0.6488 - val_acc: 0.8343\n",
      "1498/1498 [==============================] - 2s 1ms/step\n",
      "[0.701846195874768, 0.8237650201858602]\n"
     ]
    }
   ],
   "source": [
    "# 1. Pure Word2Vec model\n",
    "word2vec_model = model_cnn(params=MODEL_PARAMS)\n",
    "print(word2vec_model.summary())\n",
    "word2vec_model.fit(train_pad_tokens, train_labels_bin, batch_size=MODEL_PARAMS['batch_size'],\n",
    "                   epochs=MODEL_PARAMS['n_epochs'], validation_split=0.1)\n",
    "print(word2vec_model.evaluate(test_pad_tokens, test_labels_bin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 300, 100)     3063700     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 300, 300)     150300      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 300, 300)     30300       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 3, 300)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 3, 300)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 300)       0           max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1800)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1900)         0           flatten_3[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1900)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 70)           133070      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 70)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 35)           2485        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,855\n",
      "Trainable params: 3,379,855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 13468 samples, validate on 1497 samples\n",
      "Epoch 1/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 2.9527 - acc: 0.2014 - val_loss: 2.6694 - val_acc: 0.2158\n",
      "Epoch 2/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 2.1573 - acc: 0.2097 - val_loss: 1.5985 - val_acc: 0.2619\n",
      "Epoch 3/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 1.2259 - acc: 0.6152 - val_loss: 0.8460 - val_acc: 0.7802\n",
      "Epoch 4/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.7345 - acc: 0.8005 - val_loss: 0.6975 - val_acc: 0.8116\n",
      "Epoch 5/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.5237 - acc: 0.8531 - val_loss: 0.6350 - val_acc: 0.8183\n",
      "Epoch 6/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.3818 - acc: 0.8924 - val_loss: 0.5912 - val_acc: 0.8230\n",
      "Epoch 7/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.2762 - acc: 0.9240 - val_loss: 0.5962 - val_acc: 0.8337\n",
      "Epoch 8/10\n",
      "13468/13468 [==============================] - 55s 4ms/step - loss: 0.1928 - acc: 0.9471 - val_loss: 0.5979 - val_acc: 0.8303\n",
      "Epoch 9/10\n",
      "13468/13468 [==============================] - 54s 4ms/step - loss: 0.1342 - acc: 0.9637 - val_loss: 0.6160 - val_acc: 0.8397\n",
      "Epoch 10/10\n",
      "13468/13468 [==============================] - 53s 4ms/step - loss: 0.0930 - acc: 0.9744 - val_loss: 0.6444 - val_acc: 0.8323\n",
      "1498/1498 [==============================] - 2s 1ms/step\n",
      "[0.6910976637826265, 0.8351134842483001]\n"
     ]
    }
   ],
   "source": [
    "# 2. Doc2Vec + Word2Vec model\n",
    "doc2vec_word2vec_model = model_cnn(params=MODEL_PARAMS, doc2vec=True)\n",
    "print(doc2vec_word2vec_model.summary())\n",
    "doc2vec_word2vec_model.fit([train_pad_tokens, train_doc2vec], train_labels_bin, batch_size=MODEL_PARAMS['batch_size'],\n",
    "                           epochs=MODEL_PARAMS['n_epochs'], validation_split=0.1)\n",
    "doc2vec_word2vec_model.save('doc2vec_word2vec_model.h5')\n",
    "print(doc2vec_word2vec_model.evaluate([test_pad_tokens, test_doc2vec], test_labels_bin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 140)               14140     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 70)                9870      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 35)                2485      \n",
      "=================================================================\n",
      "Total params: 46,235\n",
      "Trainable params: 46,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13468 samples, validate on 1497 samples\n",
      "Epoch 1/10\n",
      "13468/13468 [==============================] - 1s 52us/step - loss: 2.9645 - acc: 0.2637 - val_loss: 2.4185 - val_acc: 0.2732\n",
      "Epoch 2/10\n",
      "13468/13468 [==============================] - 0s 19us/step - loss: 2.1507 - acc: 0.3210 - val_loss: 1.7675 - val_acc: 0.5010\n",
      "Epoch 3/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.6368 - acc: 0.5339 - val_loss: 1.4026 - val_acc: 0.5945\n",
      "Epoch 4/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.4837 - acc: 0.5769 - val_loss: 1.3262 - val_acc: 0.6059\n",
      "Epoch 5/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.4086 - acc: 0.5985 - val_loss: 1.2666 - val_acc: 0.6366\n",
      "Epoch 6/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.3589 - acc: 0.6058 - val_loss: 1.2438 - val_acc: 0.6366\n",
      "Epoch 7/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.3226 - acc: 0.6160 - val_loss: 1.2213 - val_acc: 0.6553\n",
      "Epoch 8/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.2902 - acc: 0.6278 - val_loss: 1.1918 - val_acc: 0.6540\n",
      "Epoch 9/10\n",
      "13468/13468 [==============================] - 0s 18us/step - loss: 1.2583 - acc: 0.6326 - val_loss: 1.1879 - val_acc: 0.6500\n",
      "Epoch 10/10\n",
      "13468/13468 [==============================] - 0s 17us/step - loss: 1.2531 - acc: 0.6378 - val_loss: 1.1797 - val_acc: 0.6593\n",
      "1498/1498 [==============================] - 0s 34us/step\n",
      "[1.2369994310256796, 0.6415220296908125]\n"
     ]
    }
   ],
   "source": [
    "# 3. Pure Doc2Vec model\n",
    "doc2vec_model = model_doc2vec(params=MODEL_PARAMS)\n",
    "print(doc2vec_model.summary())\n",
    "doc2vec_model.fit(train_doc2vec, train_labels_bin, batch_size=MODEL_PARAMS['batch_size'],\n",
    "                  epochs=MODEL_PARAMS['n_epochs'], validation_split=0.1)\n",
    "doc2vec_model.save('doc2vec_model.h5')\n",
    "print(doc2vec_model.evaluate(test_doc2vec, test_labels_bin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXERCISES\n",
    "\n",
    "# EXERCISE 1 - model\n",
    "# In this exercise you will use word vectors trained by gensim.\n",
    "# You need to tokenize the documents using gensim's vocabulary,\n",
    "# and pass the embedding matrix to the Embedding layer in model definition. Make sure to freeze the layer weights!\n",
    "\n",
    "gensim_emb_matrix = model.wv.vectors\n",
    "gensim_word_index_dict = prepare_gensim_word_index_dict(model.wv.vocab)\n",
    "gensim_train_tokens = train_data_prep.apply(tokenize, args=(gensim_word_index_dict,))\n",
    "gensim_test_tokens = test_data_prep.apply(tokenize, args=(gensim_word_index_dict,))\n",
    "\n",
    "GENSIM_MODEL_PARAMS = {\n",
    "    'input_len': 300,\n",
    "    'word_emb_size': 100,\n",
    "    'doc_emb_size': 100,\n",
    "    'filter_sizes': [5, 1],\n",
    "    'num_filters': 300,\n",
    "    'batch_size': 256,\n",
    "    'n_epochs': 1,\n",
    "    # TODO: WRITE YOUR CODE BELOW\n",
    "    'nb_tokens': ...,\n",
    "    'embedding_matrix': ...,\n",
    "    # TODO: END OF YOUR CHANGES\n",
    "    'output_len': len(ohe.categories_[0])\n",
    "}\n",
    "\n",
    "gensim_padded_train_tokens = pad_sequences(gensim_train_tokens, maxlen=MODEL_PARAMS['input_len'])\n",
    "gensim_padded_test_tokens = pad_sequences(gensim_test_tokens, maxlen=MODEL_PARAMS['input_len'])\n",
    "\n",
    "def gensim_model(params):\n",
    "    text_input = Input(shape=(params['input_len'],))\n",
    "    # TODO: WRITE YOUR CODE BELOW\n",
    "    x = Embedding(...)\n",
    "    # TODO: END OF YOUR CHANGES\n",
    "    maxpool_pool = []\n",
    "    for i in range(len(params[\"filter_sizes\"])):\n",
    "        conv = Conv1D(params['num_filters'], kernel_size=params[\"filter_sizes\"][i],\n",
    "                      kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "        maxpool_pool.append(MaxPooling1D(pool_size=params['word_emb_size'], strides=None, padding=\"valid\")(conv))\n",
    "    x = Concatenate(axis=1)(maxpool_pool)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    doc2vec_input = Input(shape=(params['doc_emb_size'],))\n",
    "    x = Concatenate(axis=1)([x, doc2vec_input])\n",
    "\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(params['output_len'] * 2)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    outp = Dense(params['output_len'], activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[text_input, doc2vec_input], outputs=outp)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "pure_gensim_model = gensim_model(params=GENSIM_MODEL_PARAMS)\n",
    "print(pure_gensim_model.summary())\n",
    "pure_gensim_model.fit([gensim_padded_train_tokens, train_doc2vec], train_labels_bin,\n",
    "                      batch_size=GENSIM_MODEL_PARAMS['batch_size'],\n",
    "                      epochs=GENSIM_MODEL_PARAMS['n_epochs'], validation_split=0.1)\n",
    "pure_gensim_model.save('pure_gensim_model.h5')\n",
    "print(pure_gensim_model.evaluate([gensim_padded_test_tokens, test_doc2vec], test_labels_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 2 - working with doc2vec representations\n",
    "# Choose 3 different offers.\n",
    "# For each of those, find 10 that are most similar using the gensim model and print their content to console\n",
    "for index, offer in train_data_prep.iloc[:3].iteritems():\n",
    "    # TODO: WRITE YOUR CODE BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
