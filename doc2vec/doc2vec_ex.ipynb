{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "from string import punctuation\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "try: \n",
    "    from doc2vec.constants import GENSIM_MODEL_PATH, TRAIN_PATH, TEST_PATH, PUNC_CHARS, STOP_WORDS, SGJP_PATH\n",
    "    from doc2vec.utils import prepare_sgjp_dict, clear_offers\n",
    "except ModuleNotFoundError:\n",
    "    # goes one folder \"up\". Can't be run multiple times or your work directory will get rekt\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    from doc2vec.constants import GENSIM_MODEL_PATH, TRAIN_PATH, TEST_PATH, PUNC_CHARS, STOP_WORDS, SGJP_PATH\n",
    "    from doc2vec.utils import prepare_sgjp_dict, clear_offers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc2vec/models/my_doc2vec_model.pickle'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-247b6a7d2ec2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGENSIM_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \"\"\"\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved %s object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_smart_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[1;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[0;32m    547\u001b[0m                                        compress, subname)\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;31m# restore attribs handled specially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mpickle\u001b[1;34m(obj, fname, protocol)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \"\"\"\n\u001b[1;32m-> 1363\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'b' for binary, needed on Windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode should be a string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shortcut_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc2vec/models/my_doc2vec_model.pickle'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "model.save(GENSIM_MODEL_PATH)\n",
    "\n",
    "# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\n",
    "\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "# Infer vector for a new document:\n",
    "\n",
    "vector = model.infer_vector([\"system\", \"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_PATH, 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "with open(TEST_PATH, 'rb') as file:\n",
    "    test_data = pickle.load(file)\n",
    "lemmatize_dict = prepare_sgjp_dict(SGJP_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e53b200c7813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                \u001b[0mstopwords_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTOP_WORDS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                \u001b[0mlemmatize_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlemmatize_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                \u001b[0mremove_punct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPUNC_CHARS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                )\n",
      "\u001b[1;32m~\\Documents\\nlp_workshops\\doc2vec\\utils.py\u001b[0m in \u001b[0;36mclear_offers\u001b[1;34m(text, stopwords_list, lemmatize_dict, remove_punct)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclear_offers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlemmatize_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# czyszczenie danych\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_word_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     seq = seq.apply(\n\u001b[0;32m     42\u001b[0m         lambda x: [item.lstrip(remove_punct).rstrip(remove_punct) if isinstance(item, str) else item for item in x])\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_2019\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(text, filters, lower, split)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_data_prep = clear_offers(data=train_data,\n",
    "                               stopwords_list=STOP_WORDS,\n",
    "                               lemmatize_dict=lemmatize_dict,\n",
    "                               remove_punct=PUNC_CHARS + punctuation\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61885     specjalista ds. wsparcia klienta czołowy produ...\n",
       "117016    kierownik sklepu stokrotka sp. z o o. – jesteś...\n",
       "11741     samodzielna księgowa etatu dynamicznie rozwija...\n",
       "59035     testera oprogramowania firma smartware rozpocz...\n",
       "40389     specjalista ds. kadr i płac www doorfin pl jes...\n",
       "82619     przedstawiciel handlowy duża firma produkcyjno...\n",
       "128492    specjalista ds. księgowości grupa balex metal ...\n",
       "1107      mechatronik utrzymanie ruchu jesteśmy nowoczes...\n",
       "81384     pracownik biurowy firma lontex została założon...\n",
       "81850     przedstawiciel medyczny dział lecznictwa otwar...\n",
       "78256     kierowca kat. c+e firma p u h. ryszard młynarc...\n",
       "65222     koordynator procesów logistycznych phoenix con...\n",
       "16191     magazyniera weilburger graphics może poszczyci...\n",
       "91613     specjalista prawnik geofizyka kraków s a. nale...\n",
       "805       radca prawny  . sporządzanie i opiniowanie dok...\n",
       "39133     sprzedawca lodów  . książeczka do celów sanita...\n",
       "137439    młodszy analityk kredytowy procesu masowego de...\n",
       "104051    specjalista ds. obsługi dokumentacji i korespo...\n",
       "55848     aplikant firma szkoleniowa z siedzibą w łodzi ...\n",
       "62524     specjalisty ds. planowania produkcji constanti...\n",
       "3295      prawnik  . wsparcie działu prawnego w bieżącyc...\n",
       "133621    koordynator ds. ekspansji  . osoba zatrudniona...\n",
       "33646     specjalista ds. analizy spoin delphi poland s ...\n",
       "31992     programisty działamy na rynku finansowym już o...\n",
       "99405     specjalista ds. rozwoju i pr ottima plus sp. z...\n",
       "31113     stażysta w zespole rekrutacyjnym  . jeżeli int...\n",
       "22109     specjalista ds. vat mddp outsourcing jest jedn...\n",
       "122718    młodszy specjalista ds. sprzedaży pgnig jest l...\n",
       "127800    handlowiec doradca klienta hurtownia techniczn...\n",
       "7340      specjalista ds. księgowo finansowych zachodnio...\n",
       "                                ...                        \n",
       "118004    programista java w zespole big data cloud  . z...\n",
       "92423     sprzedawca pilnie poszukujemy energicznych odp...\n",
       "33706     samodzielny pracownik działu kadr  . prowadzen...\n",
       "1707      blacharz ślusarz m sport poland sp. z o o. jes...\n",
       "118154    programista php opcja pl sp. z o o. to polska ...\n",
       "114737    doradca techniczno handlowy przemysł w arche c...\n",
       "128578    recepcjonistka recepcjonista wierzymy że prawd...\n",
       "81222     programista biuro projektowe urządzeń elektron...\n",
       "130410    office manager dla naszego klienta międzynarod...\n",
       "44451     doradca serwisowy s plus łopuszańska należy do...\n",
       "85013     asystent ka zarządu firma handlowa będąca jedn...\n",
       "104856    dermokonsultantka dr organic jest liderem w sp...\n",
       "50547     sprzedawca txm textilmarket jest szybko rozwij...\n",
       "94237     mechanik autoryzowany dealer samochodów marki ...\n",
       "64691     asystentka sekretarka jesteśmy stabilną i ciąg...\n",
       "66028     informatyk firma twa retail sp. z o o. s k . w...\n",
       "5202      magazynier randstad polska jest wiodącą agencj...\n",
       "114814    główny a księgowy a umowa na zastępstwo schave...\n",
       "117742    project manager  . wsparcie project managera o...\n",
       "24203     specjalista ds. obsługi klienta z językiem ang...\n",
       "99197     pracownik produkcyjny – montaż gądki grupa wor...\n",
       "15045     konstruktor elementów wentylacyjnych miejsce p...\n",
       "52603     sprzedawca visual merchandiser grupa inditex w...\n",
       "15707     doradca klienta cermag sp. z o o. to dynamiczn...\n",
       "37863     przedstawiciel handlowy producent wody mineral...\n",
       "126598    pracownik produkcyjny branża mięsna wyjazd do ...\n",
       "63846     inżynier ds. zamawiania części zamiennych miej...\n",
       "44356     pracownik magazynu  . wykształcenie min. średn...\n",
       "64113     kierownik produkcji przetwórstwo tworzyw sztuc...\n",
       "27307     przedstawiciel handlowy granulat chmielarz sp ...\n",
       "Length: 15000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
